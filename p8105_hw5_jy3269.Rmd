---
title: "p8105_hw5_jy3269"
author: "Jingyi Yao"
date: "`r Sys.Date()`"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(gtsummary)
set.seed(1)
```



# Problem 2

### 1. Describe the raw data
```{r}
raw_data <- read_csv("./data/homicide-data.csv",show_col_types = FALSE)

dim(raw_data)

colnames(raw_data)

```

\ \par

1. The raw data set contains `r nrow(raw_data)` rows of observations (homicide) and `r ncol(raw_data)` columns of variables (homicide features).

2. The variables are `r colnames(raw_data)`

3. This data set mainly documents the homicides in 50 large U.S. cities. Each row is a documented homicide, including the victim's information, the place where the homicide took place and the result.


\ \par
### 2. Create a `city_state` variable
```{r}
homicide <- raw_data %>% 
  mutate(city_state = str_c(city,", ",state)) %>% 
  select(uid,city_state,everything())   # put the newly created variable at the front

homicide %>%
  head() %>% 
  knitr::kable()   # show the first 6 rows of the homicide dataset

```

\ \par
### 3. Summarize within cities
```{r}
homicide %>% 
  group_by(city_state) %>% 
  summarize(
    total_homicides = n(),
    unsolved_homicides = sum(disposition == "Open/No arrest") + sum(disposition == "Closed without arrest")) %>% 
  arrange(desc(total_homicides)) %>%   # arranged by total_homicides counts
  knitr::kable()

```

\ \par

From the table we know that :

1. Chicago has the most total homicides (5535) and the most unsolved homicides(4073).

2. Tulsa in Alabama has only 1 case of homicide and 0 unsolved homicide.


\ \par
### 4. Focus on Baltimore, MD
```{r}
baltimore <- homicide %>% 
  filter(city_state == "Baltimore, MD") %>% 
  mutate(
    unsolved_homicides = ifelse(disposition == "Open/No arrest" | disposition == "Closed without arrest", 1,0))  # create a binary column showing the status

```



\ \par
### 5. Conduct proportion test and save the results
```{r}
result_baltimore <- prop.test(sum(baltimore$unsolved_homicides),length(baltimore$unsolved_homicides)) %>% 
  broom::tidy()   # tidy the result

result_baltimore

# the result is save in the result folder in the R project
save(result_baltimore, file = "result/results_baltimore.RData")
```
\ \par

The `prop.test` on Baltimore estimates that 64.56% of the homicides are unsolved, and the 95% confidence interval for the proportion estimate is ( 0.6275625, 0.6631599	) 


\ \par
### 6. Pull the estimated proportion and confidence intervals
```{r}
# using pull()
prop_estimate_baltimore <- result_baltimore %>% 
  pull(estimate)

lower_bound_baltimore <- result_baltimore %>% 
  pull(conf.low)

upper_bound_baltimore <- result_baltimore %>% 
  pull(conf.high)

baltimore_estimate <- list(
  "proportion_estimate" = prop_estimate_baltimore,
  "lower_CI_estimate" = lower_bound_baltimore,
  "upper_CI_estimate" = upper_bound_baltimore
) %>% 
  bind_rows()

baltimore_estimate %>% knitr::kable()

```


```{r}
# not using pull(), using select()
result_baltimore <- prop.test(sum(baltimore$unsolved_homicides),length(baltimore$unsolved_homicides)) %>% 
  broom::tidy() %>% 
  select(estimate,conf.low,conf.high)

result_baltimore %>% knitr::kable()

```


### 7. define a function
```{r}
unsolved <- function(citystate){
  # filter a city
  by_city <- homicide %>% 
    filter(city_state == citystate) %>% 
    mutate(unsolved_homicides = ifelse(disposition == "Open/No arrest" | disposition == "Closed without arrest", 1,0)) 
  
  # conduct prop test for the filtered city
    result <- prop.test(sum(by_city$unsolved_homicides),length(by_city$unsolved_homicides)) %>% 
    broom::tidy() %>% 
    select(estimate, conf.low, conf.high)
    
  # output
    result 
}
  
```

\ \par 

We define a function called `unsolved()` to get the `prop.test` result of the each city in the dataset.

The input of the function is the `city_state` name and the output is the proportion point estimate and 95% confidence interval of the estimate.


\ \par
### 8. iterate the function among each city
```{r}
cityname = unique(homicide$city_state) 

result <- expand_grid(city_state = cityname) %>% 
  mutate(prop_test_result = map(cityname, unsolved)) %>% 
  unnest(prop_test_result) %>% 
  arrange(desc(estimate))

result %>% knitr::kable(digits = 3)
```
\ \par

### 9. plot the result
```{r}
result %>%
  ggplot(aes(group = city_state, y = reorder(city_state, estimate))) + 
  geom_point(aes(x = estimate)) +
  geom_errorbar(aes(xmin = conf.low, xmax = conf.high)) +
  theme(axis.text.y = element_text(hjust = 0.5,size = 6)) +
  labs(y = "City,State", x = "Estimated Proportion and 95% CI",title = "Unsolved Homicides")

```

The x-axis is the estimated proportion of unsolved homicides and its 95% CI.

The y-axis is each city_state in the dataset.

We can tel from the plot that Chicago's unsolved homicides proportion estimate is the the highest and it is significantly higher than the rest.




\ \par
\ \par

## Problem 3

### 1. set the design element and generate 5000 samples 
```{r}
samples <- rerun(5000,rnorm(n = 30,mean = 0,sd = 5))

```

### 2. define a function to t.test 1 sample and save the estimate and p-value
```{r}
t_test <- function(mu = 0) {
  sample <- tibble(rnorm(n = 30, mean = mu, sd = 5))
  
  result <- t.test(sample) %>% 
    broom::tidy() %>% 
    select(estimate,p.value)
  
  result
}

t_test()
  
```

### 3. use the defined function to t.test 5000 samples with the same mean = 0
```{r}
mean_0 <- expand_grid(mean = 0, iteration = 1:5000) %>% 
  mutate(result = map(mean,t_test)) %>% 
  unnest(result)

head(mean_0)

```

### 4. t.test samples with different means
```{r}
mean_multi <- expand_grid(mean = 1:6, iteration = 1:5000) %>% 
  mutate(result = map(mean,t_test)) %>% 
  unnest(result)

head(mean_multi)

```

### 5. plot of power
```{r}
mean_multi %>%
  group_by(mean) %>% 
  summarize(proportion_rejected = sum(p.value < 0.05)/5000) %>% 
  ggplot(aes(x = mean,y = proportion_rejected)) +
  scale_x_continuous(limits = c(1,6), breaks = seq(1,6,1)) + 
  geom_point() + geom_path() +
  labs(x = "True Mean",y = "Power ( proportion of rejected tests )",title = "Power of t.test with different means")

```

### 6. plot of estimated means
```{r,warning=FALSE}
mean_multi %>%
  group_by(mean) %>% 
  summarize(average_estimate = mean(estimate,na.rm = T)) %>% 
  ggplot(aes(x = mean,y = average_estimate)) +
  scale_x_continuous(limits = c(1,6), breaks = seq(1,6,1)) + 
  geom_point() + geom_path() +
  labs(x = "True Mean",y = "Average Estimate Mean",title = "Estimated Means")

```

### 7. plot all the estimates vs. the rejected estimates
```{r}
rejected_estimate <- mean_multi %>% 
  filter(p.value < 0.05) %>% group_by(mean) %>% 
  summarize(average_estimate = mean(estimate,na.rm = T)) %>% 
  ungroup()

full_estimate <- mean_multi %>% 
  group_by(mean) %>% 
  summarize(average_estimate = mean(estimate,na.rm = T)) %>% 
  ungroup()
  
ggplot(full_estimate,aes(x = mean, y = average_estimate)) +
  geom_line(data = full_estimate,aes(colour = "blue")) +
  geom_line(data = rejected_estimate,aes(colour = "red")) +
  scale_color_manual(name = " ", values = c("blue" = "blue", "red" = "red"),
                     labels = c('All Estimates','Rejected Estimates'))+
  geom_point(data = full_estimate,colour = "blue") +
  geom_point(data = rejected_estimate,colour = "red") +
  scale_x_continuous(limits = c(1,6), breaks = seq(1,6,1)) +
  labs(x = "True Mean",y = "Average Estimate Mean",title = "All vs. Rejected Estimates")
  
  

```


